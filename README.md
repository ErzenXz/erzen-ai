# üß† ErzenAI - The Ultimate Open-Source AI Chat Platform

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FErzenXz%2Ferzen-ai&project-name=ErzenAI&env=VITE_CONVEX_URL,CONVEX_DEPLOY_KEY)

[![Deploy to Netlify](https://www.netlify.com/img/deploy/button.svg)](https://app.netlify.com/start/deploy?repository=https://github.com/ErzenXz/erzen-ai#VITE_CONVEX_URL=YourValue&CONVEX_DEPLOY_KEY=YourValue)

> **ErzenAI** is a revolutionary, open-source AI chat platform that unifies the power of multiple AI providers into a single, elegant interface. Built for developers, teams, and AI enthusiasts who demand flexibility, performance, and complete control over their AI interactions.

## üåü Why ErzenAI?

ErzenAI isn't just another AI chat app‚Äîit's a comprehensive AI platform designed to handle everything from casual conversations to complex reasoning tasks, code analysis, and creative projects. Whether you're a developer debugging code, a researcher analyzing data, or a creative professional generating content, ErzenAI adapts to your needs.

### üöÄ Key Highlights

- **75+ AI Models**: Access to cutting-edge models from OpenAI, Google, Anthropic, Groq, and more
- **Advanced Reasoning**: Native support for thinking/reasoning models like o1, o3, Claude, and Gemini
- **Real-time Streaming**: Lightning-fast response streaming with optimistic UI updates
- **Powerful Tools**: Integrated web search, image generation, code analysis, and more
- **Enterprise-Ready**: Built on Convex for scalability, with real-time collaboration features
- **Self-Hostable**: Complete control with easy deployment on Vercel or your own infrastructure

## ‚ú® Features Overview

### ü§ñ Multi-Provider AI Access

Access the world's most advanced AI models from a single interface:

**Built-in Providers:**

- **OpenAI**: o3-mini, o4-mini, o3, o1, GPT-4.1, GPT-4o series
- **Google AI**: Gemini 2.5 Pro, Gemini 2.0 Flash, Gemini 1.5 series
- **Anthropic**: Claude Sonnet 4.0, Claude Opus 4.0, Claude 3.5 series
- **Groq**: Ultra-fast inference with Llama 3.3, DeepSeek R1, QWQ-32B
- **OpenRouter**: Access to 15+ additional models including free options

**Additional Providers:**

- **DeepSeek**: DeepSeek Chat, DeepSeek Reasoner
- **Grok**: Grok 3 Beta, Grok Vision, Grok 2 series
- **Cohere**: Command-A, Command-R series, Aya models
- **Mistral**: Magistral, Mistral Medium/Small, Pixtral, Codestral

### üõ†Ô∏è Advanced AI Tools

**Web Intelligence:**

- **Real-time Web Search**: Tavily-powered search for current information
- **Deep Research**: Multi-query comprehensive research tool
- **URL Fetching**: Analyze and summarize web content

**Creative & Analysis:**

- **Image Generation**: AI-powered image creation with multiple styles
- **Code Analysis**: Advanced code review, debugging, and optimization
- **Mathematical Calculator**: Complex computation support

**Productivity:**

- **Smart Memory**: Context-aware conversation memory
- **DateTime Tools**: Current time and date awareness
- **Thinking Tools**: Step-by-step reasoning assistance

### üéØ Advanced Features

**Conversation Management:**

- **Branching Conversations**: Explore different discussion paths
- **Conversation Sharing**: Secure link sharing with teammates
- **Export Functionality**: Download conversations in multiple formats
- **Pin Important Chats**: Quick access to your most valuable conversations

**Customization & Control:**

- **Custom System Prompts**: Tailor AI behavior to your needs
- **Model-Specific Settings**: Temperature, reasoning effort
- **Favorite Models**: Quick access to your preferred AI models
- **Flexible Tool Configuration**: Enable/disable tools per conversation

**User Experience:**

- **Real-time Streaming**: Watch responses appear as they're generated
- **Dark/Light Themes**: Multiple color themes and system theme support
- **Responsive Design**: Perfect on desktop, tablet, and mobile
- **File Attachments**: Support for images, documents, and media files

### üîí Security & Privacy

- **Bring Your Own Keys**: Use your own API keys for unlimited access
- **Built-in Key Management**: Generous free tier with fair usage limits
- **Secure Authentication**: OAuth integration with multiple providers
- **Data Protection**: Enterprise-grade encryption and privacy controls
- **Self-Hosting**: Complete data sovereignty when self-deployed

## üí≥ Pricing & Usage

### Credit-Based System

ErzenAI uses a fair, transparent credit system for built-in API key usage:

**Free Plan** - Perfect for getting started

- 100 conversation credits/month
- 10 web searches/month
- $1.00 spending limit
- Access to all AI models
- Real-time streaming
- Conversation sharing

**Pro Plan** - For professionals _(Coming Soon)_

- 500 conversation credits/month
- 200 web searches/month
- $8.00 spending limit
- Priority model access
- Advanced features
- Team collaboration

**Ultra Plan** - For teams and power users _(Coming Soon)_

- 2,500 conversation credits/month
- 1,000 web searches/month
- $20.00 spending limit
- Custom AI instructions
- Advanced analytics
- White-label options

### Unlimited Usage

Use your own API keys for unlimited access to any supported provider without credit limitations.

## üìä ErzenAI vs Alternatives

| Feature                    | ErzenAI           | ChatGPT Plus           | Claude Pro             | Other OSS    |
| -------------------------- | ----------------- | ---------------------- | ---------------------- | ------------ |
| **Multi-Provider Access**  | ‚úÖ 75+ Models     | ‚ùå OpenAI Only         | ‚ùå Anthropic Only      | ‚ö†Ô∏è Limited   |
| **Real-time Streaming**    | ‚úÖ All Models     | ‚úÖ                     | ‚úÖ                     | ‚ö†Ô∏è Basic     |
| **Advanced Reasoning**     | ‚úÖ Native Support | ‚úÖ o1/o3 Models        | ‚úÖ Claude 3.7 Sonnet   | ‚ùå           |
| **Web Search Integration** | ‚úÖ Tavily API     | ‚úÖ Search with Bing    | ‚úÖ Research Mode       | ‚ö†Ô∏è Limited   |
| **Image Generation**       | ‚úÖ Built-in       | ‚úÖ DALL-E Integration  | ‚ùå                     | ‚ùå           |
| **Image Analysis**         | ‚úÖ Multi-modal    | ‚úÖ Vision Capabilities | ‚úÖ Vision Capabilities | ‚ö†Ô∏è Limited   |
| **Code Analysis**          | ‚úÖ Advanced       | ‚úÖ Advanced            | ‚úÖ Advanced            | ‚ö†Ô∏è Basic     |
| **Conversation Branching** | ‚úÖ                | ‚ùå                     | ‚ùå                     | ‚ùå           |
| **Tool Integrations**      | ‚úÖ 10+ Built-in   | ‚ö†Ô∏è Limited Plugins     | ‚úÖ MCP Protocol        | ‚ùå           |
| **Self-Hosting**           | ‚úÖ Full Control   | ‚ùå                     | ‚ùå                     | ‚úÖ           |
| **API Access**             | ‚úÖ Planned        | ‚úÖ                     | ‚úÖ                     | ‚ö†Ô∏è Limited   |
| **Monthly Cost**           | **Free-$20**      | $20                    | $20                    | Free         |
| **Usage Limits**           | ‚úÖ Flexible       | ‚ùå Fixed               | ‚ùå Fixed               | ‚úÖ Unlimited |

## üöÄ Performance Metrics

- **Response Time**: Sub-2 second average response initiation
- **Streaming Speed**: 50-150 tokens/second depending on provider
- **Uptime**: 99.9% availability on Vercel/Netlify
- **Concurrent Users**: Scales automatically with serverless architecture
- **Model Switching**: Instant provider/model switching without session loss

## üèóÔ∏è Technical Architecture

**Frontend:**

- **React 19** with TypeScript
- **Vite** for blazing-fast development
- **Tailwind CSS** + **Shadcn/ui** for beautiful, responsive design
- **React Markdown** with syntax highlighting and LaTeX support

**Backend & Database:**

- **Convex** for real-time backend and database
- **Convex Auth** for secure authentication
- **Real-time subscriptions** for live updates
- **File storage** with automatic text extraction

**AI Integration:**

- **Vercel AI SDK** for unified AI provider access
- **Native streaming** support for all models
- **Advanced reasoning** middleware for enhanced thinking
- **Tool calling** with comprehensive error handling

**Deployment:**

- **Vercel** optimized with SPA routing
- **Environment-based configuration**
- **Automatic HTTPS** and CDN
- **Scalable serverless architecture**

## üöÄ Quick Start

### Prerequisites

- **Node.js** 18 or later
- **pnpm** (recommended) or npm
- **Convex account** (free)

### 1. Clone & Install

```bash
git clone https://github.com/ErzenXz/erzen-ai.git
cd erzen-ai
pnpm install
```

### 2. Set Up Convex Backend

```bash
# Install Convex CLI if needed
pnpm dlx convex

# Initialize Convex (creates convex.json)
pnpm dlx convex dev
```

Follow the prompts to create a new Convex project or link to an existing one.

### 3. Configure Environment

Create `.env.local`:

```env
VITE_CONVEX_URL=your-convex-deployment-url
```

### 4. Set Up Authentication & API Keys

In your [Convex Dashboard](https://dashboard.convex.dev/):

**Authentication Setup:**

1. Create a GitHub OAuth App at [GitHub Developer Settings](https://github.com/settings/developers)
2. Set Authorization callback URL to: `https://your-convex-url.convex.site/oauth/github/callback`
3. Copy Client ID and Client Secret to your environment variables

**Environment Variables:**

```env
# Authentication (GitHub OAuth)
AUTH_GITHUB_ID=your-github-oauth-client-id
AUTH_GITHUB_SECRET=your-github-oauth-client-secret

# AI Providers (for built-in usage - optional)
OPENAI_API_KEY=your-openai-key
GOOGLE_API_KEY=your-google-ai-key
ANTHROPIC_API_KEY=your-anthropic-key
GROQ_API_KEY=your-groq-key
DEEPSEEK_API_KEY=your-deepseek-key
COHERE_API_KEY=your-cohere-key
MISTRAL_API_KEY=your-mistral-key

# Tool APIs (optional - enables enhanced features)
TAVILY_API_KEY=your-tavily-search-key
OPENWEATHER_API_KEY=your-weather-key
CLOUDFLARE_API_KEY=your-cloudflare-key
```

**API Key Providers:**

- **Tavily**: [Get API Key](https://app.tavily.com/) - For web search functionality
- **OpenWeather**: [Get API Key](https://openweathermap.org/api) - For weather tools
- **Cloudflare**: [Get API Key](https://dash.cloudflare.com/profile/api-tokens) - For image generation

### 5. Run Development Server

```bash
pnpm dev
```

Your app will be available at `http://localhost:5173`

## üîê Production Authentication

For deployments, Convex requires you to provide your own cryptographic keys for signing JSON Web Tokens (JWTs). This is a critical security measure to ensure you have full control over your authentication system.

### Generating Your Keys

You can generate the required `JWKS` and `JWT_PRIVATE_KEY` using the `convex` CLI:

```bash
npx convex auth keys
```

This command will generate two files:

- `jwks.json`: Your public JSON Web Key Set.
- `jwt_private_key.pem`: Your private key for signing tokens.

### Storing Your Keys

You need to add these keys as environment variables in your Convex Dashboard.

1.  **Copy the JWKS Key**:

    - Open `jwks.json`.
    - Copy the entire JSON content.
    - In your [Convex Dashboard](https://dashboard.convex.dev/), create a new environment variable named `JWKS` and paste the JSON content as its value.

2.  **Copy the Private Key**:
    - Open `jwt_private_key.pem`.
    - Copy the entire key, including `-----BEGIN PRIVATE KEY-----` and `-----END PRIVATE KEY-----`.
    - In your Convex Dashboard, create a new environment variable named `JWT_PRIVATE_KEY` and paste the key content as its value.

Your final production environment variables should look like this:

```env
# Authentication (GitHub OAuth)
AUTH_GITHUB_ID=your-github-oauth-client-id
AUTH_GITHUB_SECRET=your-github-oauth-client-secret

# Authentication (Convex JWT)
JWKS={"keys":[{"use":"sig","e":"AQAB","kty":"RSA","n":"..."}]}
JWT_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n"

# ... other API keys
```

> **Important**: Keep your `jwt_private_key.pem` file secure and do not commit it to version control. The `jwks.json` file can be shared as it contains public information.

## üåê Production Deployment

### Deploy to Vercel (Recommended)

1. **Connect Repository**: Import your GitHub repository to Vercel
2. **Environment Variables**: Add your `VITE_CONVEX_URL` in Vercel settings
3. **Deploy**: Vercel automatically detects Vite and configures build settings
4. **Custom Domain**: Add your custom domain in Vercel dashboard

### Deploy to Netlify

1. **Connect Repository**: Import from GitHub
2. **Build Settings**:
   - Build command: `pnpm build`
   - Publish directory: `dist`
3. **Environment Variables**: Add `VITE_CONVEX_URL`
4. **Deploy**: Automatic deployment on every push

### Self-Hosting

```bash
# Build the application
pnpm build

# Serve with any static hosting solution
# The dist/ folder contains all static assets
```

## üîß Advanced Configuration

### Model Configuration

Add custom models in `src/lib/models.ts`:

```typescript
export const MODEL_INFO: Record<string, ModelInfo> = {
  "your-custom-model": {
    id: "your-custom-model",
    displayName: "Your Custom Model",
    provider: "your-provider",
    maxInputTokens: 100000,
    maxOutputTokens: 4000,
    contextWindow: 100000,
    pricing: { input: 2.5, output: 10.0 }, // per 1M tokens
    supportsTools: true,
    isMultimodal: false,
    supportsThinking: false,
    capabilities: ["Text", "Code"],
    description: "Your custom model description",
    icon: "ü§ñ",
  },
};
```

### Provider Configuration

Add new AI providers in `convex/ai/providers/constants.ts`:

```typescript
export const PROVIDER_BASE_URLS = {
  // ... existing providers
  your_provider: "https://api.yourprovider.com/v1",
} as const;

export const SUPPORTED_PROVIDERS = [
  // ... existing providers
  "your_provider",
] as const;
```

### Tool Configuration

Enable/disable tools in `convex/ai/tools/index.ts`:

```typescript
export const TOOL_CONFIGS = {
  your_custom_tool: {
    id: "your_custom_tool",
    name: "Your Custom Tool",
    description: "Description of what your tool does",
    requiresApiKey: null, // or "provider-name"
    category: "utility",
  },
};
```

### Theme Customization

Modify themes in `tailwind.config.cjs`:

```javascript
theme: {
  extend: {
    colors: {
      primary: {
        DEFAULT: "hsl(var(--primary))",
        foreground: "hsl(var(--primary-foreground))",
      },
      // Add your custom colors
    }
  }
}
```

## ü§ù Contributing

We welcome contributions! Here's how to get started:

### Development Setup

```bash
# Fork the repository
git clone your-fork
cd erzen-ai
pnpm install

# Create feature branch
git checkout -b feature/your-feature-name

# Make changes and test
pnpm dev

# Submit pull request
```

### Contribution Guidelines

- **Code Quality**: Follow TypeScript best practices
- **Testing**: Ensure all features work with multiple AI providers
- **Documentation**: Update README for new features
- **UI/UX**: Maintain consistency with existing design patterns

### Areas for Contribution

- ü§ñ **New AI Providers**: Add support for additional AI services
- üõ†Ô∏è **Tools**: Create new tools for enhanced AI capabilities
- üé® **UI/UX**: Improve user interface and experience
- üì± **Mobile**: Enhance mobile responsiveness
- üîí **Security**: Strengthen authentication and privacy features
- üåê **Internationalization**: Add multi-language support

## üìã Roadmap

### Short Term (Q1 2025)

- [ ] **Team Collaboration**: Multi-user conversation sharing
- [ ] **API Access**: REST API for programmatic access
- [ ] **Plugin System**: Third-party tool integration
- [ ] **Advanced Analytics**: Usage statistics and insights

### Medium Term (Q2-Q3 2025)

- [ ] **Mobile Apps**: Native iOS and Android applications
- [ ] **Enterprise Features**: SSO, advanced admin controls
- [ ] **Custom AI Training**: Fine-tuning capabilities
- [ ] **Workflow Automation**: AI-powered task automation

### Long Term (Q4 2025+)

- [ ] **Multi-Modal AI**: Advanced vision and audio processing
- [ ] **AI Agents**: Autonomous task completion
- [ ] **Integration Hub**: Connect with popular productivity tools
- [ ] **On-Premise**: Enterprise self-hosting solutions

## üîß Troubleshooting

### Common Issues

**Build/Development Issues:**

```bash
# Clear all caches and reinstall
rm -rf node_modules pnpm-lock.yaml
pnpm install

# Reset Convex
pnpm dlx convex dev --reset
```

**Authentication Problems:**

- Verify GitHub OAuth callback URL matches your Convex deployment
- Check that `AUTH_GITHUB_ID` and `AUTH_GITHUB_SECRET` are correctly set
- Ensure your GitHub OAuth app is active and properly configured

**API Key Issues:**

- Test your API keys directly with provider APIs
- Check rate limits and billing on your provider accounts
- Verify environment variables are set in Convex dashboard, not just locally

**Deployment Issues:**

- Ensure `VITE_CONVEX_URL` is set correctly in your hosting platform
- Check that all environment variables are properly configured
- Verify your Convex project is deployed and accessible

### Performance Optimization

```bash
# Enable production mode
NODE_ENV=production pnpm build

# Optimize bundle size
pnpm dlx vite-bundle-analyzer dist
```

## üÜò Support & Community

### Getting Help

- üìñ **Documentation**: Comprehensive guides and API reference
- üí¨ **GitHub Discussions**: Community support and feature requests
- üêõ **Issues**: Bug reports and feature requests
- üìß **Contact**: Direct support for enterprise users

### Community

- ‚≠ê **Star the Repository**: Show your support
- üç¥ **Fork & Contribute**: Help improve the platform
- üì¢ **Share**: Spread the word about ErzenAI
- üíù **Sponsor**: Support ongoing development

## üìÑ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## üéØ Why Choose ErzenAI?

**For Developers:**

- Multi-model access for different coding tasks
- Advanced code analysis and debugging tools
- Real-time collaboration with team members
- Self-hostable for complete control

**For Teams:**

- Unified AI access across your organization
- Conversation sharing and collaboration
- Cost-effective with built-in API key management
- Enterprise-ready security and privacy

**For AI Enthusiasts:**

- Access to the latest AI models and features
- Open-source with active development
- Extensible tool system for custom workflows
- Community-driven feature development

**For Enterprises:**

- Self-hosting options for data sovereignty
- Flexible pricing with your own API keys
- Advanced user management and analytics
- Professional support and customization

---

<div align="center">

**üöÄ Ready to experience the future of AI chat?**

[**Get Started Now**](https://erzen-ai.vercel.app) | [**View Demo**](https://erzen-ai.vercel.app/homepage) | [**Join Community**](https://github.com/ErzenXz/erzen-ai/discussions)

Made with ‚ù§Ô∏è by Erzen Krasniqi

</div>
